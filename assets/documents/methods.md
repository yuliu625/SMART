# Methods

## LLM Methods
### Long Context
使用长上下文能力的LLM，输入原始的文本，模型可以做到:
- 全局分析和审视输入内容。
- 快速分析文本内容。
- 自动分类和标签添加。(我常用的做法。)

可能的问题:
- 不是专用模型而是普通模型，价格可能会非常昂贵。
- 长上下文推理速度慢。

### Structured Output
具有function-calling的模型，可以进行:
- 提取关键信息。
- 以给定指令中的schema进行输出。(我构建过足够好的工具实现这一点。)

可能的问题:
- 输出更多的是离散标签，更多使用于分类任务。(我尝试使用过置信度标签机制，但是效果并不明显。)
- 如果需要，可以训练不具有function-calling能力的模型拥有这项能力，但是有可能带来模型其他方面性能下降。

### LRM
2025年研究的热点，具有显式思维过程输出的推理模型，可以做到:
- 输出思考的过程，在输出回答前进行推理。
- 更强的可解释性，以自然语言可视模型思维链。

可能的问题:
- 支持的模型较少，价格昂贵，速度慢。
- 幻觉率比相同架构模型更高(post-training中RL的缺陷)。
- 现有模型，思考过程控制不完全，思维缺陷。(疯狂输出大量token，浪费推理资源。)
- 现有模型，思考和决策可能会存在不一致。(我目前感兴趣的研究内容之一。)

### Old Method
2025年前会使用的方法:
- LLM as Classifier: 使用比encoder-only模型更大参数规模的LLM作为分类器的base。但是，没有完全利用LLM的能力，仅第一个token的训练与pre-training的目的并不完全匹配，可能会很低效。
- SFT: 将已有数据构建为SFT数据进行训练。成本很高，很多时候不如使用更大参数规模的模型。(现有学术界的困局，没有算力和数据。)
- RL: 用已有数据构建reward-model或reward-function。比SFT的可解释性更高，但是训练更加困难。

2025可以做的方向:
- 小模型具有大模型特定领域的能力。post-training一个小模型。例如8B参数规模的小模型，通过数据集或训练方法的优势，获得当前领域大模型的性能，常见为400B-700B。(例如上财post-training的金融模型，实际基于qwen系列的7B模型，领域能力和deepseek-reasoner相当。)
- 提出评价指标。构建高质量领域数据集，对现有LLM进行评估，进行对比和揭示缺陷。2025年学术界的很多工作是这样。

## Embedding Model Methods
使用embedding-model进行文本相似度对比:
- 使用contrastive-learning训练的embedding-model(老一些的embedding-model并不是)，得到具有全局语义信息的embedding。
- 可直接用于回归任务当中。
- 有zero-shot任务的模型。(我的分析是这些模型只能理解低级语义信息。)

可能的问题:
- 可解释性: 不如以自然语言输出的LLM好，虽然可以使用一些数值分析和可视化方法。
- 可比性: 只能确定编码后的embedding相对位置是相似的，不同embedding-model的结果并不具有可比性。
- 对齐: 如果是不同维度的embedding，不能直接对比。

## Agentic Method
我的毕业论文中的设计:
- 异构agent: 用具有多种能力的agent进行处理，长上下文的LLM提取全局语义，性能好的标准模型进行推理分析，LRM进行总结。
- 层次记忆机制: 具有特定专家技能的agent仅持有自己的记忆，具有规划、推理、分析能力的agent共享高层次记忆。
- 自我优化: 设计具体的机制，应对不同的分析对象，发生针对性的分析方法和流程。
- 多模态: 不只使用和理解文本信息，还包括图、表信息。

